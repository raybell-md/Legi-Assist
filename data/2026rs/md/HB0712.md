START OF PAGE 1
HOUSE BILL 712

D3 6lr1291

By: Delegate Grammer
Introduced and read first time: February 2, 2026
Assigned to: Judiciary

A BILL ENTITLED

1 AN ACT concerning

2 Civil Actions – Product Liability – Artificial Intelligence Systems

3 FOR the purpose of establishing a cause of action against a developer of a certain artificial
4 intelligence system for defective design, failure to provide adequate instruction or
5 warning, and breach of express warranty; establishing that a deployer of a certain
6 artificial intelligence system may be sued in lieu of a developer under certain
7 circumstances; establishing a certain rebuttable presumption that an artificial
8 intelligence system is not dangerous or defective if a developer engaged in certain
9 testing and evaluation procedures, mitigated and disclosed foreseeable risks, and,
10 under certain circumstances, considered and mitigated risks to minors; establishing
11 a certain rebuttable presumption in an action against a deployer that an artificial
12 intelligence system is not dangerous or defective if the deployer implemented and
13 adhered to a certain risk management policy; authorizing the Attorney General to
14 bring an action against a developer or deployer of an artificial intelligence system for
15 harm caused by a dangerous or defective product; establishing that contributory
16 negligence is not a defense to an action under this Act and that recovery by a plaintiff
17 shall be reduced by the percentage of fault attributable to the plaintiff; establishing
18 that a developer and a deployer may be held jointly and severally liable in an action
19 under this Act; and generally relating to artificial intelligence system product
20 liability.

21 BY adding to
22 Article – Courts and Judicial Proceedings
23 Section 3–2701 through 3–2706 to be under the new subtitle “Subtitle 27. Artificial
24 Intelligence Systems Product Liability”
25 Annotated Code of Maryland
26 (2020 Replacement Volume and 2025 Supplement)

27 Preamble

EXPLANATION: CAPITALS INDICATE MATTER ADDED TO EXISTING LAW.
[Brackets] indicate matter deleted from existing law. *hb0712*
END OF PAGE 1

START OF PAGE 2
2 HOUSE BILL 712

1 WHEREAS, Artificial intelligence systems are products that shift decision–making
2 power and responsibility away from persons to software–based systems, often without
3 direct human oversight; and

4 WHEREAS, While this technology provides great benefits, the deployment of these
5 products has resulted in measurable harm to individuals and businesses; and

6 WHEREAS, Developers of high–impact artificial intelligence systems have an
7 obligation to make such products safe when used in reasonably foreseeable ways; and

8 WHEREAS, Deployers of these products also have an obligation to ensure that these
9 products are used in a way that does not materially affect an individual’s rights; and

10 WHEREAS, Maryland’s laws on artificial intelligence systems need to be expanded
11 to better protect Marylanders from harm; now, therefore,

12 SECTION 1. BE IT ENACTED BY THE GENERAL ASSEMBLY OF MARYLAND,
13 That the Laws of Maryland read as follows:

14 Article – Courts and Judicial Proceedings

15 SUBTITLE 27. ARTIFICIAL INTELLIGENCE SYSTEMS PRODUCT LIABILITY.

16 3–2701.

17 (A) IN THIS SUBTITLE THE FOLLOWING WORDS HAVE THE MEANINGS
18 INDICATED.

19 (B) “ARTIFICIAL INTELLIGENCE SYSTEM” MEANS AN ENGINEERED OR
20 MACHINE–BASED SYSTEM WITH VARYING LEVELS OF AUTONOMY THAT CAN, FOR
21 EXPLICIT OR IMPLICIT OBJECTIVES, INFER FROM THE INPUTS IT RECEIVES HOW TO
22 GENERATE OUTPUTS THAT CAN INFLUENCE PHYSICAL OR VIRTUAL ENVIRONMENTS.

23 (C) “CONSEQUENTIAL DECISION” MEANS A DECISION THAT HAS A LEGAL OR
24 SIMILARLY SIGNIFICANT EFFECT ON AN INDIVIDUAL’S ACCESS TO THE CRIMINAL
25 JUSTICE SYSTEM, HOUSING, EMPLOYMENT, CREDIT, EDUCATION, HEALTH CARE, OR
26 INSURANCE.

27 (D) (1) “DEPLOYER” MEANS A PERSON, INCLUDING A DEVELOPER, THAT
28 USES OR OPERATES AN ARTIFICIAL INTELLIGENCE SYSTEM FOR USE BY THE
29 DEPLOYER OR THIRD PARTIES.

30 (2) “DEPLOYER” DOES NOT INCLUDE AN INDIVIDUAL OR SMALL
31 BUSINESS THAT HAS FEWER THAN:
END OF PAGE 2

START OF PAGE 3
HOUSE BILL 712 3

1 (I) 20 EMPLOYEES; OR

2 (II) 10,000 USERS OF ITS PRODUCT.

3 (E) (1) “DEVELOPER” MEANS A PERSON THAT DESIGNS, CODES,
4 PRODUCES, OWNS, OR SUBSTANTIALLY MODIFIES AN ARTIFICIAL INTELLIGENCE
5 SYSTEM FOR USE BY A DEVELOPER OR FOR USE BY THIRD PARTIES.

6 (2) “DEVELOPER” DOES NOT INCLUDE A PERSON THAT USES AN OPEN
7 SOURCE ARTIFICIAL INTELLIGENCE SYSTEM AND DOES NOT SUBSTANTIALLY
8 MODIFY THE ARTIFICIAL INTELLIGENCE SYSTEM.

9 (F) “DESIGN” MEANS THE INTENDED OR KNOWN PHYSICAL AND MATERIAL
10 CHARACTERISTICS OF A PRODUCT, INCLUDING:

11 (1) ANY INTENDED OR KNOWN FORMULATION OR CONTENT OF THE
12 PRODUCT; AND

13 (2) THE USUAL RESULT OF THE INTENDED METHOD OF
14 DEVELOPMENT OR OTHER PROCESS USED TO PRODUCE THE PRODUCT, INCLUDING
15 UNEXPECTED SKILLS OR BEHAVIORS THAT APPEAR IN A PRODUCT.

16 (G) “EXPRESS WARRANTY” MEANS ANY MATERIAL, POSITIVE STATEMENT,
17 AFFIRMATION OF FACT, PROMISE, OR DESCRIPTION RELATING TO A PRODUCT,
18 INCLUDING A SAMPLE OR MODEL OF A PRODUCT.

19 (H) “GENERATIVE ARTIFICIAL INTELLIGENCE SYSTEM” MEANS AN
20 ARTIFICIAL INTELLIGENCE SYSTEM THAT CAN GENERATE DERIVED SYNTHETIC
21 CONTENT, SUCH AS TEXT, IMAGES, VIDEO, AND AUDIO, THAT EMULATES THE
22 STRUCTURE AND CHARACTERISTICS OF THE ARTIFICIAL INTELLIGENCE SYSTEM’S
23 TRAINING DATA.

24 (I) “HARM” MEANS:

25 (1) DAMAGE TO PROPERTY OTHER THAN THE ARTIFICIAL
26 INTELLIGENCE SYSTEM ITSELF;

27 (2) PERSONAL PHYSICAL, FINANCIAL, OR REPUTATIONAL INJURY,
28 ILLNESS, OR DEATH;

29 (3) MENTAL OR PHYSIOLOGICAL ANGUISH, EMOTIONAL HARM, OR
30 DISTORTION OF A PERSON’S BEHAVIOR THAT WOULD BE HIGHLY OFFENSIVE TO A
31 REASONABLE PERSON; OR
END OF PAGE 3

START OF PAGE 4
4 HOUSE BILL 712

1 (4) ANY LOSS OF CONSORTIUM OR SERVICES, OR OTHER LOSS
2 DERIVING FROM ANY TYPE OF HARM DESCRIBED UNDER THIS SUBSECTION.

3 (J) “HIGH–IMPACT ARTIFICIAL INTELLIGENCE SYSTEM” MEANS ANY
4 ARTIFICIAL INTELLIGENCE SYSTEM, REGARDLESS OF THE NUMBER OF
5 PARAMETERS AND SUPERVISION STRUCTURE, THAT:

6 (1) IS USED, OR REASONABLY FORESEEABLY MAY BE USED, AS A
7 CONTROLLING FACTOR IN MAKING CONSEQUENTIAL DECISIONS;

8 (2) IS USED, OR REASONABLY FORESEEABLY MAY BE USED, TO
9 CATEGORIZE GROUPS OF PERSONS BY PROTECTED CHARACTERISTICS, SUCH AS
10 RACE, ETHNIC ORIGIN, OR RELIGIOUS BELIEF;

11 (3) IS USED, OR REASONABLY FORESEEABLY MAY BE USED, IN THE
12 DIRECT MANAGEMENT OR OPERATION OF CRITICAL INFRASTRUCTURE;

13 (4) IS USED, OR REASONABLY FORESEEABLY MAY BE USED, IN A
14 VEHICLE, IN A MEDICAL DEVICE, OR IN THE SAFETY SYSTEM OF A VEHICLE OR
15 MEDICAL DEVICE;

16 (5) IS USED, OR REASONABLY FORESEEABLY MAY BE USED, TO
17 ENGAGE IN A SYNTHETIC RELATIONSHIP; OR

18 (6) EXHIBITS, OR COULD BE EASILY MODIFIED TO EXHIBIT, HIGH
19 LEVELS OF PERFORMANCE AT TASKS THAT POSE A SERIOUS RISK TO ECONOMIC
20 SECURITY OR PUBLIC HEALTH OR SAFETY.

21 (K) (1) “MATERIAL FACT” MEANS ANY SPECIFIC CHARACTERISTIC OR
22 QUALITY OF THE PRODUCT.

23 (2) “MATERIAL FACT” DOES NOT INCLUDE A GENERAL OPINION
24 ABOUT THE PRODUCT OR ITS QUALITY.

25 (L) “METHOD OF DEVELOPMENT” MEANS THE SELECTION OF TRAINING
26 DATA FOR THE PRODUCT, INCLUDING THE TRAINING, TESTING, AUDITING, AND
27 FINE–TUNING OF THE PRODUCT.

28 (M) “PERSON” MEANS ANY INDIVIDUAL, CORPORATION, COMPANY,
29 ASSOCIATION, FIRM, PARTNERSHIP, SOCIETY, JOINT STOCK COMPANY, OR ANY
30 OTHER ENTITY, INCLUDING ANY GOVERNMENTAL ENTITY OR UNINCORPORATED
31 ASSOCIATION OF PERSONS.
END OF PAGE 4

START OF PAGE 5
HOUSE BILL 712 5

1 (N) “PRODUCT” MEANS A HIGH–IMPACT ARTIFICIAL INTELLIGENCE
2 SYSTEM OR A GENERATIVE ARTIFICIAL INTELLIGENCE SYSTEM.

3 (O) “SYNTHETIC RELATIONSHIP” MEANS A SERIES OF INTERACTIONS
4 BETWEEN AN INDIVIDUAL AND AN ARTIFICIAL INTELLIGENCE SYSTEM THAT MIMICS
5 HUMAN INTERACTION AND EMOTIONAL RESPONSES.

6 3–2702.

7 THIS SUBTITLE DOES NOT APPLY TO ARTIFICIAL INTELLIGENCE SYSTEMS
8 USED ONLY FOR PEER–REVIEWED SCIENTIFIC RESEARCH.

9 3–2703.

10 (A) A PERSON MAY BRING AN ACTION IN ACCORDANCE WITH THIS SECTION
11 AGAINST A DEVELOPER OR DEPLOYER FOR HARM CAUSED BY A PRODUCT THAT IS
12 DANGEROUS OR DEFECTIVE.

13 (B) IN AN ACTION AGAINST A DEVELOPER ALLEGING HARM CAUSED BY A
14 DANGEROUS OR DEFECTIVE PRODUCT DUE TO THE DEFECTIVE DESIGN OF THE
15 PRODUCT, THE PLAINTIFF SHALL PROVE BY A PREPONDERANCE OF THE EVIDENCE
16 THAT THE HARM WAS PROXIMATELY CAUSED BY THE FAILURE OF THE DEVELOPER
17 TO EXERCISE REASONABLE CARE AND THAT, AT THE TIME THE PRODUCT LEFT THE
18 DEVELOPER’S CONTROL:

19 (1) THE DEVELOPER KNEW OR REASONABLY SHOULD HAVE KNOWN
20 OF THE DESIGN DEFECT THAT CAUSED THE HARM;

21 (2) THE DEVELOPER ACCOUNTED FOR INTENDED USES AND
22 REASONABLY FORESEEABLE UNINTENDED USES OF THE PRODUCT; AND

23 (3) A TECHNOLOGICALLY FEASIBLE AND PRACTICAL ALTERNATIVE
24 DESIGN EXISTED THAT WOULD HAVE MITIGATED OR AVOIDED THE FORESEEABLE
25 RISK OF HARM WITHOUT SIGNIFICANTLY IMPAIRING THE INTENDED USE OF THE
26 PRODUCT.

27 (C) (1) IN THIS SUBSECTION, “ADEQUATE INSTRUCTION OR WARNING”
28 MEANS AN INSTRUCTION OR A WARNING REGARDING A DANGER THAT WOULD
29 SUFFICIENTLY INFORM A REASONABLY PRUDENT PERSON ON THE SAFE USE AND
30 DANGERS OF A PRODUCT.

31 (2) IN AN ACTION AGAINST A DEVELOPER ALLEGING HARM CAUSED
END OF PAGE 5

START OF PAGE 6
6 HOUSE BILL 712

1 BY A DANGEROUS OR DEFECTIVE PRODUCT DUE TO A FAILURE TO PROVIDE
2 ADEQUATE INSTRUCTION OR WARNING, A PLAINTIFF SHALL PROVE BY A
3 PREPONDERANCE OF THE EVIDENCE THAT THE HARM WAS PROXIMATELY CAUSED
4 BY THE FAILURE TO PROVIDE ADEQUATE INSTRUCTION OR WARNING AND THAT, AT
5 THE TIME THE PRODUCT LEFT THE DEVELOPER’S CONTROL, THE DEVELOPER KNEW
6 OR REASONABLY SHOULD HAVE KNOWN OF THE DANGER POSED BY THE PRODUCT.

7 (3) IT IS A DEFENSE TO AN ACTION AGAINST A DEVELOPER FOR HARM
8 CAUSED BY A FAILURE TO INSTRUCT OR WARN THAT:

9 (I) THE USER OR CONSUMER OF THE PRODUCT WAS AT LEAST
10 17 YEARS OLD; AND

11 (II) THE PRODUCT DANGER WAS KNOWN OR OPEN AND OBVIOUS
12 TO THE USER OR CONSUMER OF THE PRODUCT, OR SHOULD HAVE BEEN KNOWN OR
13 OPEN AND OBVIOUS TO THE USER OR CONSUMER OF THE PRODUCT.

14 (D) IN AN ACTION AGAINST A DEVELOPER ALLEGING HARM CAUSED BY A
15 DANGEROUS OR DEFECTIVE PRODUCT DUE TO THE FAILURE OF THE PRODUCT TO
16 CONFORM TO AN EXPRESS WARRANTY, THE PLAINTIFF SHALL PROVE BY A
17 PREPONDERANCE OF THE EVIDENCE THAT THE HARM WAS PROXIMATELY CAUSED
18 BY THE FAILURE OF THE DEVELOPER TO EXERCISE REASONABLE CARE AND THAT:

19 (1) THE PLAINTIFF REASONABLY RELIED ON AN EXPRESS WARRANTY
20 MADE BY A DEVELOPER ABOUT A MATERIAL FACT CONCERNING THE SAFETY OF THE
21 PRODUCT; AND

22 (2) (I) 1. THE PRODUCT FAILED TO CONFORM TO THE EXPRESS
23 WARRANTY; AND

24 2. THE FAILURE OF THE PRODUCT TO CONFORM TO THE
25 EXPRESS WARRANTY RESULTED IN THE HARM; OR

26 (II) 1. THE EXPRESS WARRANTY WAS UNTRUE; AND

27 2. HAD THE EXPRESS WARRANTY BEEN TRUE, THE HARM
28 WOULD NOT HAVE OCCURRED.

29 (E) (1) A DEPLOYER MAY BE HELD LIABLE IN PLACE OF A DEVELOPER IN
30 AN ACTION UNDER THIS SECTION IF THE DEPLOYER:

31 (I) MADE A MATERIAL AND SUBSTANTIAL CHANGE TO THE
32 PRODUCT; OR
END OF PAGE 6

START OF PAGE 7
HOUSE BILL 712 7

1 (II) INTENTIONALLY MISUSED THE PRODUCT CONTRARY TO AN
2 EXPRESS WARRANTY AND THAT MISUSE WAS THE PROXIMATE CAUSE OF HARM
3 SUFFERED BY A PLAINTIFF.

4 (2) (I) USE OF A PRODUCT THAT IS INTENDED BY THE DEVELOPER
5 OF THE PRODUCT DOES NOT CONSTITUTE A MISUSE OR MATERIAL OR SUBSTANTIAL
6 CHANGE OF THE PRODUCT UNDER THIS SECTION.

7 (II) IF A DEVELOPER DOES NOT SPECIFY AN INTENDED USE FOR
8 THE PRODUCT, INTENDED USE MAY BE INFERRED BY THE TARGETED MARKET AND
9 MANNER OF DISTRIBUTION OF THE PRODUCT.

10 (3) A DEPLOYER LICENSING A PRODUCT MAY NOT BE HELD LIABLE TO
11 A PLAINTIFF FOR A VIOLATION UNDER THIS SECTION SOLELY BY REASON OF
12 OWNERSHIP OR USE OF A PRODUCT.

13 (F) IN AN ACTION BROUGHT UNDER THIS SECTION, THERE IS A REBUTTABLE
14 PRESUMPTION THAT A PRODUCT IS NOT DANGEROUS OR DEFECTIVE IF:

15 (1) IN AN ACTION AGAINST A DEVELOPER, THE DEVELOPER:

16 (I) CONDUCTED A DOCUMENTED TESTING, EVALUATION,
17 VERIFICATION, VALIDATION, AND AUDITING OF THE PRODUCT CONSISTENT WITH
18 INDUSTRY BEST PRACTICES;

19 (II) MITIGATED FORESEEABLE RISKS TO THE EXTENT
20 POSSIBLE;

21 (III) DISCLOSED FORESEEABLE RISKS AND MITIGATION TACTICS
22 DIRECTLY TO DEPLOYERS AND CONSUMERS; AND

23 (IV) IF THE PRODUCT IS DESIGNED FOR OR REASONABLY LIKELY
24 TO BE USED BY MINORS, CONSIDERED AND MITIGATED FORESEEABLE RISKS TO
25 MINORS USING THE PRODUCT, INCLUDING:

26 1. THE IMPACT OF THE PRODUCT ON COGNITIVE AND
27 EMOTIONAL DEVELOPMENT;

28 2. THE IMPLEMENTATION OF AGE AND CONTENT
29 RESTRICTIONS; AND

30 3. PROVIDING CLEAR, ACCESSIBLE DISCLOSURES TO
END OF PAGE 7

START OF PAGE 8
8 HOUSE BILL 712

1 DEPLOYERS, CONSUMERS, AND GUARDIANS ABOUT POTENTIAL RISKS; OR

2 (2) IN AN ACTION AGAINST A DEPLOYER, THE DEPLOYER
3 IMPLEMENTED AND ADHERED TO A RISK MANAGEMENT POLICY THAT:

4 (I) SPECIFIES THE POLICY BY WHICH THE DEPLOYER WILL
5 IDENTIFY, DOCUMENT, AND MITIGATE ANY RISK, ESPECIALLY TO MINOR USERS,
6 THAT IS REASONABLY FORESEEABLE;

7 (II) IS CONSISTENT WITH INDUSTRY BEST PRACTICES;

8 (III) IS REASONABLE IN LIGHT OF:

9 1. THE SIZE AND COMPLEXITY OF THE DEPLOYER;

10 2. THE NATURE AND SCOPE OF THE PRODUCT,
11 INCLUDING THE INTENDED USES AND UNINTENDED USES, AS WELL AS ANY
12 MODIFICATION MADE TO THE SYSTEM BY THE DEPLOYER; AND

13 3. THE DATA THAT THE SYSTEM, ONCE DEPLOYED,
14 PROCESSES AS INPUTS; AND

15 (IV) IS ELECTRONICALLY AVAILABLE TO ITS EMPLOYEES AND TO
16 THE ATTORNEY GENERAL ON REQUEST.

17 3–2704.

18 (A) THE ATTORNEY GENERAL MAY BRING AN ACTION AGAINST A
19 DEVELOPER OR A DEPLOYER FOR HARM CAUSED BY A DANGEROUS OR DEFECTIVE
20 PRODUCT DESCRIBED IN § 3–2703 OF THIS SUBTITLE.

21 (B) (1) IN AN ACTION BROUGHT UNDER THIS SECTION, THE ATTORNEY
22 GENERAL MAY OBTAIN:

23 (I) INJUNCTIVE RELIEF;

24 (II) A CIVIL PENALTY;

25 (III) DAMAGES, RESTITUTION, OR OTHER COMPENSATION ON
26 BEHALF OF AN INDIVIDUAL WHO HAS BEEN HARMED BY AN ARTIFICIAL
27 INTELLIGENCE SYSTEM; AND

28 (IV) ANY OTHER RELIEF THAT THE ATTORNEY GENERAL
END OF PAGE 8

START OF PAGE 9
HOUSE BILL 712 9

1 CONSIDERS APPROPRIATE.

2 (2) IF THE USE OF THE SOFTWARE CAUSES PERSONAL INJURY OR
3 DEATH, A CIVIL PENALTY IMPOSED UNDER THIS SUBSECTION MAY NOT EXCEED THE
4 APPLICABLE LIMITATION ON NONECONOMIC DAMAGES UNDER § 3–2A–09 OF THIS
5 TITLE.

6 (C) IN AN ACTION BROUGHT BY THE ATTORNEY GENERAL UNDER THIS
7 SECTION, THE ATTORNEY GENERAL IS ENTITLED TO RECOVER THE COSTS OF THE
8 ACTION FOR THE USE OF THE STATE.

9 (D) BEFORE BRINGING AN ACTION UNDER THIS SECTION SEEKING
10 INJUNCTIVE RELIEF, THE ATTORNEY GENERAL SHALL PROVIDE WRITTEN NOTICE
11 TO A DEVELOPER OR DEPLOYER AT LEAST 30 DAYS BEFORE COMMENCEMENT OF
12 THE ACTION THAT INCLUDES A DETAILED DESCRIPTION OF THE BASIS OF THE CLAIM
13 AND, WHEN POSSIBLE, THE OPPORTUNITY TO CURE ANY CONDITION GIVING RISE TO
14 THE CLAIM.

15 3–2705.

16 (A) (1) CONTRIBUTORY NEGLIGENCE IS NOT A DEFENSE TO AN ACTION
17 BROUGHT UNDER THIS SUBTITLE AND RECOVERY BY A PLAINTIFF MAY NOT BE
18 BARRED REGARDLESS OF THE PLAINTIFF’S DEGREE OF FAULT.

19 (2) RECOVERY BY A PLAINTIFF UNDER THIS SUBTITLE SHALL BE
20 REDUCED IN PROPORTION TO THE PERCENTAGE OF FAULT ATTRIBUTABLE TO THE
21 PLAINTIFF.

22 (B) A DEVELOPER AND A DEPLOYER MAY BE HELD JOINTLY AND SEVERALLY
23 LIABLE FOR THE PORTION OF HARM TO THE PLAINTIFF ATTRIBUTED TO THE
24 DEVELOPER AND DEPLOYER.

25 (C) IT IS NOT A DEFENSE TO AN ACTION BROUGHT UNDER THIS SUBTITLE
26 THAT AN ARTIFICIAL INTELLIGENCE SYSTEM AUTONOMOUSLY CAUSED THE HARM
27 TO THE PLAINTIFF.

28 3–2706.

29 THIS SUBTITLE:

30 (1) SUPPLEMENTS ANY COMMON LAW TORT LIABILITY CAUSE OF
31 ACTION AND ANY STATE PRODUCT LIABILITY LAWS; AND
END OF PAGE 9

START OF PAGE 10
10 HOUSE BILL 712

1 (2) MAY NOT BE INTERPRETED TO PROHIBIT ANY PRODUCT
2 LIABILITY CAUSE OF ACTION INVOLVING A PRODUCT BROUGHT UNDER A DIFFERENT
3 CLAIM UNDER PRODUCT LIABILITY COMMON LAW OR STATUTE.

4 SECTION 2. AND BE IT FURTHER ENACTED, That this Act shall take effect
5 October 1, 2026.
END OF PAGE 10